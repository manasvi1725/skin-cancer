# -*- coding: utf-8 -*-
"""training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gHiz1jcjIW4msKGe4iNnAc6in0RBrhdH
"""

!kaggle datasets download manasvi12/skin-cancer-isic-2020-segmented-both

import zipfile
zip_ref = zipfile.ZipFile('/content/skin-cancer-isic-2020-segmented-both.zip', 'r')
zip_ref.extractall('/content')
zip_ref.close()

import os
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import to_categorical
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.regularizers import l2

from PIL import Image
import cv2

# Paths to train and test directories
TRAIN_ORIGINAL_DIR = '/content/original images/Skin cancer ISIC The International Skin Imaging Collaboration/Train'
TRAIN_SEGMENTED_DIR = '/content/segmented images/segmented/Train'
TEST_ORIGINAL_DIR = '/content/original images/Skin cancer ISIC The International Skin Imaging Collaboration/Test'
TEST_SEGMENTED_DIR = '/content/segmented images/segmented/Test'

IMG_SIZE = (224, 224)  # Resize images to 224x224
CLASS_NAMES = sorted(os.listdir(TRAIN_ORIGINAL_DIR))  # Get class names from folder structure
NUM_CLASSES = len(CLASS_NAMES)

# Mapping class names to numeric labels
class_to_label = {class_name: idx for idx, class_name in enumerate(CLASS_NAMES)}
label_to_class = {idx: class_name for class_name, idx in class_to_label.items()}

import os
import cv2
import numpy as np

def load_combined_images(original_dir, segmented_dir, img_size=(224, 224)):
    images = []
    labels = []
    for class_name in os.listdir(original_dir):
        orig_class_path = os.path.join(original_dir, class_name)
        seg_class_path = os.path.join(segmented_dir, class_name)

        label = class_to_label[class_name]

        for img_name in os.listdir(orig_class_path):
            try:
                # Handle different formats for original and segmented images
                orig_img_path = os.path.join(orig_class_path, img_name)

                # Check for corresponding segmented image (e.g., with .tiff extension)
                base_name = os.path.splitext(img_name)[0]  # Remove extension
                seg_img_path = os.path.join(seg_class_path, f"{base_name}.tiff")

                # Load and resize original image
                orig_img = cv2.imread(orig_img_path)
                if orig_img is None:
                    raise FileNotFoundError(f"Original image not found: {orig_img_path}")
                orig_img = cv2.resize(orig_img, img_size)
                orig_img = orig_img / 255.0

                # Load and resize segmented image
                seg_img = cv2.imread(seg_img_path, cv2.IMREAD_GRAYSCALE)
                if seg_img is None:
                    raise FileNotFoundError(f"Segmented image not found: {seg_img_path}")
                seg_img = cv2.resize(seg_img, img_size)
                seg_img = seg_img / 255.0
                seg_img = np.expand_dims(seg_img, axis=-1)  # Add channel dimension

                # Combine original and segmented images
                combined_img = np.concatenate((orig_img, seg_img), axis=-1)

                images.append(combined_img)
                labels.append(label)
            except Exception as e:
                print(f"Error loading image {img_name}: {e}")

    return np.array(images), np.array(labels)

# Load training and testing data
X_train, y_train = load_combined_images(TRAIN_ORIGINAL_DIR, TRAIN_SEGMENTED_DIR)
X_test, y_test = load_combined_images(TEST_ORIGINAL_DIR, TEST_SEGMENTED_DIR)

# Convert labels to one-hot encoding
y_train = to_categorical(y_train, NUM_CLASSES)
y_test = to_categorical(y_test, NUM_CLASSES)

# Data augmentation
datagen = ImageDataGenerator(
    rotation_range=30,
    width_shift_range=0.3,
    height_shift_range=0.3,
    zoom_range=0.3,
    shear_range=0.2,
    horizontal_flip=True,
    vertical_flip=False,
    brightness_range=[0.8, 1.2]
)
datagen.fit(X_train)

from sklearn.model_selection import train_test_split

X_train, x_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

model = Sequential([
    # First Convolutional Block
    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 4)),
    MaxPooling2D((2, 2)),
    BatchNormalization(),

    # Second Convolutional Block
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    BatchNormalization(),

    # Third Convolutional Block
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    BatchNormalization(),
    # Fully Connected Layers
    Flatten(),
    Dense(units=128, activation='relu', kernel_regularizer=l2(0.0010)),
    Dropout(0.3),  # Dropout for regularization
    Dense(units=64, activation='relu', kernel_regularizer=l2(0.001)),
    Dropout(0.3),  # Dropout for regularization
    Dense(NUM_CLASSES, activation='softmax')  # Output Layer for multi-class classification
])
model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])

model.summary()

from re import X
from tensorflow.keras.callbacks import ReduceLROnPlateau

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1
)

history = model.fit(
    X_train, y_train,
    validation_data=(x_val, y_val),
    epochs=100,
    batch_size=32,
    callbacks=[reduce_lr]
)

# Evaluate the model
loss, accuracy = model.evaluate(X_train, y_train)
print(f"Traning Accuracy: {accuracy * 100:.2f}%")

loss, accuracy = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {accuracy * 100:.2f}%")

# Classification report
y_pred = np.argmax(model.predict(X_test), axis=1)
y_test_labels = np.argmax(y_test, axis=1)
print(classification_report(y_test_labels, y_pred, target_names=CLASS_NAMES))

# Assuming y_test is one-hot encoded
y_pred = model.predict(X_test)  # Get model predictions
y_pred_classes = y_pred.argmax(axis=1)  # Convert predictions to class indices
y_true_classes = y_test.argmax(axis=1)  # Convert true labels to class indices

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Calculate metrics
accuracy = accuracy_score(y_true_classes, y_pred_classes)
precision = precision_score(y_true_classes, y_pred_classes, average='weighted')
recall = recall_score(y_true_classes, y_pred_classes, average='weighted')
f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')

# Print the metrics as percentages
print(f"Accuracy: {accuracy * 100:.2f}%")
print(f"Precision: {precision * 100:.2f}%")
print(f"Recall: {recall * 100:.2f}%")
print(f"F1 Score: {f1 * 100:.2f}%")

import numpy as np
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Assuming 'classes' is defined elsewhere in your code
# ...

# Predict probabilities
y_pred_probs = model.predict(X_test)

# Convert probabilities to class labels (multilabel-indicator format)
# Assuming a threshold of 0.5 for assigning classes
threshold = 0.5
y_pred_multilabel = (y_pred_probs > threshold).astype(int)

# If y_test is also in multilabel-indicator format:
cm = confusion_matrix(y_test.argmax(axis=1), y_pred_multilabel.argmax(axis=1))  # Compare argmax for both

# OR, if y_test is in multiclass format:
# cm = confusion_matrix(y_test, y_pred_multilabel.argmax(axis=1))  # Compare multiclass with argmax of multilabel

sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

import matplotlib.pyplot as plt

# Plot training and validation accuracy
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Plot training and validation loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

model.save('/content/model.h5')

from google.colab import files

files.download('/content/model.h5')